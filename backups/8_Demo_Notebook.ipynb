{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac5a915-6057-4165-a965-58c4813c036a",
   "metadata": {},
   "source": [
    "# Import Libraries (env = conda_pytorch_p37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d36172a-10fd-4812-ab7b-175d951fe65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import tqdm\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from fastai.medical.imaging import *\n",
    "from fastai.vision.all import *\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as ptc\n",
    "from tqdm import tqdm # for getting a progress bar on loops\n",
    "import pymysql\n",
    "import time\n",
    "from PIL import Image\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4e1937-1674-4ff1-b0b4-3e84e0795650",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00fb563a-49cd-42d9-ba3e-86c3b0330834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 2 µs, total: 12 µs\n",
      "Wall time: 17.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Bring in Dicom Metadata\n",
    "\n",
    "# Read a Dicom Image\n",
    "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    \n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "               \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "        \n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_dcm_contents(file):\n",
    "    dcm = Path(f_path + file).dcmread()    \n",
    "    properties = [string for string in dir(dcm) if prog.match(string).group(0)!='']\n",
    "    dict1 = {'file': file.replace('.dicom', '')}    \n",
    "    dict1.update( { what: dcm[what].value for what in properties if isinstance(dcm[what].value, (bytes, bytearray))!=True } )\n",
    "    return dict1\n",
    "\n",
    "\n",
    "# Convert to JPG and resize to max 1024 pixels\n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h,w) = image.shape[:2]\n",
    "    \n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    \n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w*r), height)\n",
    "        \n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h*r))\n",
    "    \n",
    "    # resize image\n",
    "    img = cv2.resize(image, dim, interpolation=inter)\n",
    "    \n",
    "    # return the resized image\n",
    "    return img\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20f2f55f-d896-4fce-b3fe-d922dbc938e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/214 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The pixel data with transfer syntax JPEG 2000 Image Compression (Lossless Only), cannot be read because Pillow lacks the JPEG 2000 plugin",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mread_xray\u001b[0;34m(path, voi_lut, fix_monochrome)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VA4/lib/python3.9/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36mpixel_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1881\u001b[0m         \"\"\"\n\u001b[0;32m-> 1882\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_pixel_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1883\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"numpy.ndarray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pixel_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VA4/lib/python3.9/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36mconvert_pixel_data\u001b[0;34m(self, handler_name)\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_pixel_data_using_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_pixel_data_without_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_convert_pixel_data_using_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VA4/lib/python3.9/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36m_convert_pixel_data_without_handler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1554\u001b[0m             \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailable_handlers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m         )\n\u001b[0;32m-> 1556\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mlast_exception\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_do_pixel_data_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VA4/lib/python3.9/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36m_convert_pixel_data_without_handler\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailable_handlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1536\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_pixel_data_conversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1537\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VA4/lib/python3.9/site-packages/pydicom/dataset.py\u001b[0m in \u001b[0;36m_do_pixel_data_conversion\u001b[0;34m(self, handler)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0;31m# Use the handler to get a 1D numpy array of the pixel data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;31m# Will raise an exception if no pixel data element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pixeldata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pixel_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_pixel_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/VA4/lib/python3.9/site-packages/pydicom/pixel_data_handlers/pillow_handler.py\u001b[0m in \u001b[0;36mget_pixeldata\u001b[0;34m(ds)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mHAVE_JPEG2K\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtransfer_syntax\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mPillowJPEG2000TransferSyntaxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         raise NotImplementedError(\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0;34mf\"The pixel data with transfer syntax {transfer_syntax.name}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;34mf\"cannot be read because Pillow lacks the JPEG 2000 plugin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The pixel data with transfer syntax JPEG 2000 Image Compression (Lossless Only), cannot be read because Pillow lacks the JPEG 2000 plugin"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f_path = 'DemoDicomImages/'\n",
    "files = [f for f in os.listdir(f_path) if os.path.isfile(os.path.join(f_path, f))]\n",
    "prog = re.compile('^[A-Z]*')\n",
    "\n",
    "# Bring in Dicom FilesBring in Dicom Metadata\n",
    "\n",
    "df = pd.DataFrame( [ get_dcm_contents(file) for file in files ] )\n",
    "# df = val_files.append(val_files, ignore_index=True)\n",
    "\n",
    "# Convert to JPG and resize to max 1024 pixels\n",
    "val_outdir = 'DemoConversionToJPG/'\n",
    "\n",
    "for files in os.listdir(val_outdir):\n",
    "    path = os.path.join(val_outdir, files)\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except OSError:\n",
    "        os.remove(path)\n",
    "\n",
    "if not os.path.exists(val_outdir):\n",
    "    os.mkdir(val_outdir)\n",
    "    \n",
    "# Convert DICOM to JPG via openCV\n",
    "val_list = [os.path.basename(x) for x in glob.glob(f_path + './*.dicom')]\n",
    "# print(val_list)\n",
    "for f in tqdm(val_list):  \n",
    "    if not os.path.exists(f_path + f[:-5] + 'jpg'):\n",
    "        img = read_xray(f_path + f) # read dicom image\n",
    "        img = resize(img,height=1024)\n",
    "        cv2.imwrite(val_outdir + f.replace('.dicom','.jpg'),img) # write jpg image\n",
    "        \n",
    "val_jpg_files = glob.glob(f'{val_outdir}/*.jpg')\n",
    "print (f'Number of val_jpg_test files in {val_outdir}: {len(val_jpg_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c3965e-d5b6-4388-9939-c071fc9201bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>BitsAllocated</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>Columns</th>\n",
       "      <th>HighBit</th>\n",
       "      <th>LossyImageCompression</th>\n",
       "      <th>NumberOfFrames</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>PatientSex</th>\n",
       "      <th>PhotometricInterpretation</th>\n",
       "      <th>PixelAspectRatio</th>\n",
       "      <th>PixelRepresentation</th>\n",
       "      <th>PixelSpacing</th>\n",
       "      <th>Rows</th>\n",
       "      <th>SamplesPerPixel</th>\n",
       "      <th>WindowCenter</th>\n",
       "      <th>WindowWidth</th>\n",
       "      <th>RescaleIntercept</th>\n",
       "      <th>RescaleSlope</th>\n",
       "      <th>PatientSize</th>\n",
       "      <th>PatientWeight</th>\n",
       "      <th>LargestImagePixelValue</th>\n",
       "      <th>SmallestImagePixelValue</th>\n",
       "      <th>LossyImageCompressionMethod</th>\n",
       "      <th>LossyImageCompressionRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0d825340b08e816f7d8f28c7c7809a31</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2330</td>\n",
       "      <td>15</td>\n",
       "      <td>00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000Y</td>\n",
       "      <td>M</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.141, 0.141]</td>\n",
       "      <td>2485</td>\n",
       "      <td>1</td>\n",
       "      <td>41367.0</td>\n",
       "      <td>65435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05711a72a0819422965daa93f30b6f75</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1994</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.175, 0.175]</td>\n",
       "      <td>2430</td>\n",
       "      <td>1</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0403dda5a9bf46457517b604869d530d</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>3072</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>O</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.139000, 0.139000]</td>\n",
       "      <td>3072</td>\n",
       "      <td>1</td>\n",
       "      <td>3507.0</td>\n",
       "      <td>4199.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05e951c63e80999f13e6e09e7ec8439a</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1994</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.175, 0.175]</td>\n",
       "      <td>2430</td>\n",
       "      <td>1</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2517</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>060Y</td>\n",
       "      <td>F</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.139, 0.139]</td>\n",
       "      <td>3028</td>\n",
       "      <td>1</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>011295e0bcdc7636569ab73bfdcc4450</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1994</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.175, 0.175]</td>\n",
       "      <td>2430</td>\n",
       "      <td>1</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0168eb925aa6f28a78b16134792f5d0e</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2336</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>MONOCHROME1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.15, 0.15]</td>\n",
       "      <td>2836</td>\n",
       "      <td>1</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0c8cb29888d314a0a8cfd0f8278af74c</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2642</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.125, 0.125]</td>\n",
       "      <td>3170</td>\n",
       "      <td>1</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>4579.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0b4e8de571c66cf889f2beb35182974b</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1994</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>O</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.175, 0.175]</td>\n",
       "      <td>2430</td>\n",
       "      <td>1</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0b9f58b6f12a231738723f4d2dda0312</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>2520</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>MONOCHROME2</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.139, 0.139]</td>\n",
       "      <td>3032</td>\n",
       "      <td>1</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>4096.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file  BitsAllocated  BitsStored  Columns  \\\n",
       "0    0d825340b08e816f7d8f28c7c7809a31             16          16     2330   \n",
       "1    05711a72a0819422965daa93f30b6f75             16          12     1994   \n",
       "2    0403dda5a9bf46457517b604869d530d             16          14     3072   \n",
       "3    05e951c63e80999f13e6e09e7ec8439a             16          12     1994   \n",
       "4    004f33259ee4aef671c2b95d54e4be68             16          12     2517   \n",
       "..                                ...            ...         ...      ...   \n",
       "209  011295e0bcdc7636569ab73bfdcc4450             16          12     1994   \n",
       "210  0168eb925aa6f28a78b16134792f5d0e             16          12     2336   \n",
       "211  0c8cb29888d314a0a8cfd0f8278af74c             16          12     2642   \n",
       "212  0b4e8de571c66cf889f2beb35182974b             16          12     1994   \n",
       "213  0b9f58b6f12a231738723f4d2dda0312             16          12     2520   \n",
       "\n",
       "     HighBit LossyImageCompression  NumberOfFrames PatientAge PatientSex  \\\n",
       "0         15                    00             1.0       000Y          M   \n",
       "1         11                    00             NaN        NaN          O   \n",
       "2         13                   NaN             1.0          Y          O   \n",
       "3         11                    00             NaN        NaN          O   \n",
       "4         11                    00             NaN       060Y          F   \n",
       "..       ...                   ...             ...        ...        ...   \n",
       "209       11                    00             NaN        NaN          M   \n",
       "210       11                    00             NaN        NaN          O   \n",
       "211       11                    00             NaN        NaN              \n",
       "212       11                    00             NaN        NaN          O   \n",
       "213       11                    00             NaN        NaN          M   \n",
       "\n",
       "    PhotometricInterpretation PixelAspectRatio  PixelRepresentation  \\\n",
       "0                 MONOCHROME2             None                    0   \n",
       "1                 MONOCHROME2              NaN                    0   \n",
       "2                 MONOCHROME2              NaN                    0   \n",
       "3                 MONOCHROME2              NaN                    0   \n",
       "4                 MONOCHROME2           [1, 1]                    0   \n",
       "..                        ...              ...                  ...   \n",
       "209               MONOCHROME2              NaN                    0   \n",
       "210               MONOCHROME1              NaN                    0   \n",
       "211               MONOCHROME2              NaN                    0   \n",
       "212               MONOCHROME2              NaN                    0   \n",
       "213               MONOCHROME2           [1, 1]                    0   \n",
       "\n",
       "             PixelSpacing  Rows  SamplesPerPixel  WindowCenter  WindowWidth  \\\n",
       "0          [0.141, 0.141]  2485                1       41367.0      65435.0   \n",
       "1          [0.175, 0.175]  2430                1        2047.0       4096.0   \n",
       "2    [0.139000, 0.139000]  3072                1        3507.0       4199.0   \n",
       "3          [0.175, 0.175]  2430                1        2047.0       4096.0   \n",
       "4          [0.139, 0.139]  3028                1        2048.0       4096.0   \n",
       "..                    ...   ...              ...           ...          ...   \n",
       "209        [0.175, 0.175]  2430                1        2047.0       4096.0   \n",
       "210          [0.15, 0.15]  2836                1        2047.0       4095.0   \n",
       "211        [0.125, 0.125]  3170                1        2070.0       4579.0   \n",
       "212        [0.175, 0.175]  2430                1        2047.0       4096.0   \n",
       "213        [0.139, 0.139]  3032                1        2048.0       4096.0   \n",
       "\n",
       "     RescaleIntercept  RescaleSlope  PatientSize  PatientWeight  \\\n",
       "0                 NaN           NaN          NaN            NaN   \n",
       "1                 0.0           1.0          NaN            NaN   \n",
       "2                 0.0           1.0          NaN            NaN   \n",
       "3                 0.0           1.0          NaN            NaN   \n",
       "4                 0.0           1.0          NaN            NaN   \n",
       "..                ...           ...          ...            ...   \n",
       "209               0.0           1.0          NaN            NaN   \n",
       "210               0.0           1.0          NaN            NaN   \n",
       "211               0.0           1.0          NaN            NaN   \n",
       "212               0.0           1.0          NaN            NaN   \n",
       "213               0.0           1.0          NaN            NaN   \n",
       "\n",
       "     LargestImagePixelValue  SmallestImagePixelValue  \\\n",
       "0                       NaN                      NaN   \n",
       "1                       NaN                      NaN   \n",
       "2                       NaN                      NaN   \n",
       "3                       NaN                      NaN   \n",
       "4                    4095.0                      0.0   \n",
       "..                      ...                      ...   \n",
       "209                     NaN                      NaN   \n",
       "210                     NaN                      NaN   \n",
       "211                     NaN                      NaN   \n",
       "212                     NaN                      NaN   \n",
       "213                  4095.0                      0.0   \n",
       "\n",
       "    LossyImageCompressionMethod  LossyImageCompressionRatio  \n",
       "0                           NaN                         NaN  \n",
       "1                           NaN                         NaN  \n",
       "2                           NaN                         NaN  \n",
       "3                           NaN                         NaN  \n",
       "4                           NaN                         NaN  \n",
       "..                          ...                         ...  \n",
       "209                         NaN                         NaN  \n",
       "210                         NaN                         NaN  \n",
       "211                         NaN                         NaN  \n",
       "212                         NaN                         NaN  \n",
       "213                         NaN                         NaN  \n",
       "\n",
       "[214 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c164d9a-e546-47ad-8a2c-fdda46505967",
   "metadata": {},
   "source": [
    "### Insert headers and jpg images to SingleStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d93b6d6-3e09-4979-a3d8-a3fb54dd41e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to Inserted jpg files  2021-12-10 02:44:12.714499\n",
      "100  Elapse Time 0:00:01.489719\n",
      "200  Elapse Time 0:00:03.087259\n",
      "Inserted  214  End Time  2021-12-10 02:44:15.998968  Elapse Time  0:00:03.284480\n",
      "CPU times: user 2.56 s, sys: 39.2 ms, total: 2.59 s\n",
      "Wall time: 3.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s2conn = create_engine('mysql+pymysql://root:Sglstrpw34@172.31.62.112:3306/PatientRecords')\n",
    "df.to_sql('ImageHeaderdf', s2conn, if_exists='replace', index = False)\n",
    "## copy ImageHeaderdf to ImageHeader\n",
    "\n",
    "# df = pd.read_sql_table('ImageHeaderdf', s2conn)\n",
    "\n",
    "def convertToBinaryData(ImageFile):\n",
    "    # Convert digital data to binary format\n",
    "    with open(ImageFile, 'rb') as file:\n",
    "        binaryData = file.read()\n",
    "    return binaryData\n",
    "\n",
    "\n",
    "def insertBLOB(ImageID, ImagePath, ImageFile):\n",
    "    #print(\"Inserting BLOB into JPGImages table\")\n",
    "    # try:\n",
    "    mycursor = s2conn.cursor()\n",
    "\n",
    "    sql_insert_blob_query = \"\"\" INSERT IGNORE INTO JPGImages\n",
    "                      (file, ImagePath, Image) VALUES (%s,%s,%s)\"\"\"\n",
    "\n",
    "    jpgImage = convertToBinaryData(ImageFile)\n",
    "\n",
    "    # Convert data into tuple format\n",
    "    insert_blob_tuple = (ImageID, ImagePath, jpgImage)\n",
    "    result = mycursor.execute(sql_insert_blob_query, insert_blob_tuple)\n",
    "    s2conn.commit()\n",
    "    #print(\"Image inserted successfully as a BLOB into Images table\", result)\n",
    "\n",
    "    #except pymysql.connect.Error as error:\n",
    "        #print(\"Failed inserting BLOB data into S2 table {}\".format(error))\n",
    "\n",
    "    #finally:\n",
    "        #if s2conn.is_connected():\n",
    "    mycursor.close()\n",
    "    \n",
    "    \n",
    "# Main\n",
    "directory = '/home/ubuntu/vinbigdata/DemoConversionToJPG/'\n",
    "jpgCount = 0\n",
    "\n",
    "startTime = datetime.now()\n",
    "print(\"Starting to Inserted jpg files \",startTime)\n",
    "\n",
    "s2conn = pymysql.connect(\n",
    "    user='root',\n",
    "    password='Sglstrpw34',\n",
    "    host='172.31.62.112',\n",
    "    port=3306,\n",
    "    database='Images')\n",
    "\n",
    "# iterate over files in\n",
    "# that directory\n",
    "for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        file = os.path.splitext(os.path.basename(os.path.basename(f)))[0]\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f) and f.endswith(\".jpg\"):\n",
    "            insertBLOB(file, directory, f)\n",
    "            jpgCount += 1\n",
    "            if jpgCount % 100 == 0:\n",
    "                print (jpgCount, \" Elapse Time\", (datetime.now() - startTime))\n",
    "\n",
    "s2conn.close()\n",
    "print(\"Inserted \",jpgCount, \" End Time \",datetime.now(), \" Elapse Time \",(datetime.now() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5439d-aae7-42d6-8c04-c3fa00e379df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['file',\n",
    "#            'BitsAllocated',\n",
    "#            'BitsStored',\n",
    "#            'Columns',\n",
    "#            'HighBit',\n",
    "#            'LossyImageCompression',\n",
    "#            'PatientSex',\n",
    "#            'PhotometricInterpretation',\n",
    "#            'PixelRepresentation',\n",
    "#            'PixelSpacing',\n",
    "#            'RescaleIntercept',\n",
    "#            'RescaleSlope',\n",
    "#            'Rows',\n",
    "#            'SamplesPerPixel',\n",
    "#            'WindowCenter',\n",
    "#            'WindowWidth',\n",
    "#            'PatientSize',\n",
    "#            'PatientWeight',\n",
    "#            'PixelAspectRatio',\n",
    "#            'PatientAge',\n",
    "#            'LossyImageCompressionRatio',\n",
    "#            'LargestImagePixelValue',\n",
    "#            'SmallestImagePixelValue',\n",
    "#            'LossyImageCompressionMethod',\n",
    "#            'NumberOfFrames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1d89c2-960b-4672-879c-f97868c7fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are some Python package conflicts so we will send Metadata to S2 here and bring it back in on environment Conda_Anaconda3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c84bff-1d15-42c7-a7c6-b35938f014bb",
   "metadata": {},
   "source": [
    "# Model Inference on Validation images (env = Conda_Anaconda3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "948e1f15-84ae-4f0c-8e7f-fa30eb37c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np, pandas as pd\n",
    "from glob import glob\n",
    "import shutil, os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "from IPython.display import Image, clear_output\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b73922c-bf77-44a3-bd8a-06bfc9d26fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.10.0+cu102 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16160MB, multi_processor_count=80)\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ac4f1349-255f-4a77-b8e3-78835ae278e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model format conversion\n",
    "def yolo2voc(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "    \n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "    \n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "# Functions\n",
    "def GeneralEnsemble(dets, iou_thresh = 0.5, weights=None):\n",
    "    assert(type(iou_thresh) == float)\n",
    "    \n",
    "    ndets = len(dets)\n",
    "    \n",
    "    if weights is None:\n",
    "        w = 1/float(ndets)\n",
    "        weights = [w]*ndets\n",
    "    else:\n",
    "        assert(len(weights) == ndets)\n",
    "        \n",
    "        s = sum(weights)\n",
    "        for i in range(0, len(weights)):\n",
    "            weights[i] /= s\n",
    "\n",
    "    out = list()\n",
    "    used = list()\n",
    "    \n",
    "    for idet in range(0,ndets):\n",
    "        det = dets[idet]\n",
    "        for box in det:\n",
    "            if box in used:\n",
    "                continue\n",
    "                \n",
    "            used.append(box)\n",
    "            # Search the other detectors for overlapping box of same class\n",
    "            found = []\n",
    "            for iodet in range(0, ndets):\n",
    "                odet = dets[iodet]\n",
    "                \n",
    "                if odet == det:\n",
    "                    continue\n",
    "                \n",
    "                bestbox = None\n",
    "                bestiou = iou_thresh\n",
    "                for obox in odet:\n",
    "                    if not obox in used:\n",
    "                        # Not already used\n",
    "                        if box[4] == obox[4]:\n",
    "                            # Same class\n",
    "                            iou = computeIOU(box, obox)\n",
    "                            if iou > bestiou:\n",
    "                                bestiou = iou\n",
    "                                bestbox = obox\n",
    "                                \n",
    "                if not bestbox is None:\n",
    "                    w = weights[iodet]\n",
    "                    found.append((bestbox,w))\n",
    "                    used.append(bestbox)\n",
    "                            \n",
    "            # Now we've gone through all other detectors\n",
    "            if len(found) == 0:\n",
    "                new_box = list(box)\n",
    "                new_box[5] /= ndets\n",
    "                out.append(new_box)\n",
    "            else:\n",
    "                allboxes = [(box, weights[idet])]\n",
    "                allboxes.extend(found)\n",
    "                \n",
    "                xc = 0.0\n",
    "                yc = 0.0\n",
    "                bw = 0.0\n",
    "                bh = 0.0\n",
    "                conf = 0.0\n",
    "                \n",
    "                wsum = 0.0\n",
    "                for bb in allboxes:\n",
    "                    w = bb[1]\n",
    "                    wsum += w\n",
    "\n",
    "                    b = bb[0]\n",
    "                    xc += w*b[0]\n",
    "                    yc += w*b[1]\n",
    "                    bw += w*b[2]\n",
    "                    bh += w*b[3]\n",
    "                    conf += w*b[5]\n",
    "                    #print(f\"conf = {conf}\")\n",
    "                \n",
    "                xc /= wsum\n",
    "                yc /= wsum\n",
    "                bw /= wsum\n",
    "                bh /= wsum    \n",
    "\n",
    "                new_box = [xc, yc, bw, bh, box[4], conf]\n",
    "                out.append(new_box)\n",
    "    return out\n",
    "    \n",
    "def getCoords(box):\n",
    "    x1 = float(box[0]) - float(box[2])/2\n",
    "    x2 = float(box[0]) + float(box[2])/2\n",
    "    y1 = float(box[1]) - float(box[3])/2\n",
    "    y2 = float(box[1]) + float(box[3])/2\n",
    "    return x1, x2, y1, y2\n",
    "    \n",
    "def computeIOU(box1, box2):\n",
    "    x11, x12, y11, y12 = getCoords(box1)\n",
    "    x21, x22, y21, y22 = getCoords(box2)\n",
    "    \n",
    "    x_left   = max(x11, x21)\n",
    "    y_top    = max(y11, y21)\n",
    "    x_right  = min(x12, x22)\n",
    "    y_bottom = min(y12, y22)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0    \n",
    "        \n",
    "    intersect_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = (x12 - x11) * (y12 - y11)\n",
    "    box2_area = (x22 - x21) * (y22 - y21)        \n",
    "    \n",
    "    iou = intersect_area / (box1_area + box2_area - intersect_area)\n",
    "    return iou\n",
    "\n",
    "# Function to transform the YOLOV5 output to the format the Ensemble function expects. \n",
    "\n",
    "def transform_object(df,tmp,flag):\n",
    "    list_of_floats=[]\n",
    "    for item in tmp:\n",
    "        list_of_floats.append(float(item))\n",
    "        \n",
    "    tm=int(len(list_of_floats)/6)\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    checkobj=[]\n",
    "    for i in range(tm):\n",
    "          \n",
    "        j=i*6\n",
    "        k=j\n",
    "        l=k+6\n",
    "            \n",
    "        checkobj.append(k)\n",
    "        xmin=list_of_floats[k+2]\n",
    "        ymin=list_of_floats[k+3]\n",
    "        xmax=list_of_floats[k+4]\n",
    "        ymax=list_of_floats[k+5]\n",
    "            \n",
    "        box_w=xmax-xmin\n",
    "        box_h=ymax-ymin\n",
    "        box_x=xmin+(box_w/2)\n",
    "        box_y=ymin+box_h/2\n",
    "            \n",
    "        list1=[box_x,box_y,box_w,box_h,int(list_of_floats[k]),list_of_floats[k+1]]\n",
    "        \n",
    "        list2.append(list1)        \n",
    "        list1=[]\n",
    "    if flag==0:\n",
    "        return checkobj\n",
    "    else:\n",
    "        return list2\n",
    "    \n",
    "#https://www.kaggle.com/prashantkikani/vinbigdata-ensemble-post-processing?scriptVersionId=56245340\n",
    "\n",
    "def divide(l, n):\n",
    "    '''\n",
    "    divide submission string into group of 6\n",
    "    '''\n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33848aca-3792-4433-bcc3-ffa9af370ca4",
   "metadata": {},
   "source": [
    "# Bring in Dicom header information for Demo Files from SingleStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21fe3de1-f96a-4d5d-859f-05687ad66155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/default.py:410: SAWarning: Exception attempting to detect unicode returns: ProgrammingError('(pymysql.err.ProgrammingError) (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \\'CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1\\' at line 1\")')\n",
      "  \"detect unicode returns: %r\" % de\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sqlalchemy/dialects/mysql/reflection.py:62: SAWarning: Unknown schema content: '  , SHARD KEY () '\n",
      "  util.warn(\"Unknown schema content: %r\" % line)\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/home/ubuntu/vinbigdata/')\n",
    "s2conn = create_engine('mysql+pymysql://root:Sglstrpw34@172.31.62.112:3306/PatientRecords')\n",
    "\n",
    "test_df = pd.read_sql_table('ImageHeaderdf', s2conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8eedb58d-a1c9-422b-9bf6-daf2c78e7625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>BitsAllocated</th>\n",
       "      <th>BitsStored</th>\n",
       "      <th>HeaderColumns</th>\n",
       "      <th>HighBit</th>\n",
       "      <th>LossyImageCompression</th>\n",
       "      <th>PatientSex</th>\n",
       "      <th>PhotometricInterpretation</th>\n",
       "      <th>PixelRepresentation</th>\n",
       "      <th>PixelSpacing</th>\n",
       "      <th>...</th>\n",
       "      <th>WindowWidth</th>\n",
       "      <th>PatientSize</th>\n",
       "      <th>PatientWeight</th>\n",
       "      <th>PixelAspectRatio</th>\n",
       "      <th>PatientAge</th>\n",
       "      <th>LossyImageCompressionRatio</th>\n",
       "      <th>LargestImagePixelValue</th>\n",
       "      <th>SmallestImagePixelValue</th>\n",
       "      <th>LossyImageCompressionMethod</th>\n",
       "      <th>NumberOfFrames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file, BitsAllocated, BitsStored, HeaderColumns, HighBit, LossyImageCompression, PatientSex, PhotometricInterpretation, PixelRepresentation, PixelSpacing, RescaleIntercept, RescaleSlope, NumberOfRows, SamplesPerPixel, WindowCenter, WindowWidth, PatientSize, PatientWeight, PixelAspectRatio, PatientAge, LossyImageCompressionRatio, LargestImagePixelValue, SmallestImagePixelValue, LossyImageCompressionMethod, NumberOfFrames]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 25 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e5f844-74a7-40d9-bcc2-802f5dba8014",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcbc14c-14e5-43b3-b2de-8ed9d319073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fold_exp = ['exp26']\n",
    "test_dir = f'/home/ubuntu/vinbigdata/DemoConversionToJPG/'\n",
    "os.chdir('/home/ubuntu/vinbigdata/yolov5')\n",
    "\n",
    "for fold, exp in enumerate(fold_exp):\n",
    "    weights_dir = f'/home/ubuntu/vinbigdata/yolov5/runs/train/{exp}/weights/best.pt'\n",
    "    os.chdir('/home/ubuntu/vinbigdata/yolov5/')\n",
    "    \n",
    "    !python detect.py --weights $weights_dir\\\n",
    "    --img 1024\\\n",
    "    --conf 0.1\\\n",
    "    --iou 0.4\\\n",
    "    --source $test_dir\\\n",
    "    --save-txt --save-conf --exist-ok\n",
    "    \n",
    "    image_ids = []\n",
    "    PredictionStrings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df1065-b401-4c09-a7bb-dbe9d720d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "    for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n",
    "        image_id = file_path.split('/')[-1].split('.')[0]\n",
    "        # print(image_id)\n",
    "        # print(test_df.loc[test_df.file==image_id,['Columns']].values[0])\n",
    "        # print(test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0])\n",
    "        w, h = test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0]\n",
    "        f = open(file_path, 'r')\n",
    "        data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "        data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "        bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n",
    "        for idx in range(len(bboxes)):\n",
    "            bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n",
    "        image_ids.append(image_id)\n",
    "        PredictionStrings.append(' '.join(bboxes))\n",
    "\n",
    "    # credit / source: https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer\n",
    "    pred_df = pd.DataFrame({'file':image_ids,\n",
    "                            'PredictionString':PredictionStrings})\n",
    "    # Needs to be the dataframe with \n",
    "    df = pd.merge(test_df, pred_df, on = 'file', how = 'left').fillna(\"14 1 0 0 1 1\")\n",
    "    df = df[['file', 'PredictionString']]\n",
    "\n",
    "    os.chdir('/home/ubuntu/vinbigdata/')\n",
    "\n",
    "    # # remove files and folders from yolov5/runs/detect/exp/\n",
    "    # dir = '/home/ubuntu/vinbigdata/yolov5/runs/detect/exp/'\n",
    "    # for files in os.listdir(dir):\n",
    "    #     path = os.path.join(dir, files)\n",
    "    #     try:\n",
    "    #         shutil.rmtree(path)\n",
    "    #     except OSError:\n",
    "    #         os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8053e5d-03f4-4d9e-8272-54e74cb5540f",
   "metadata": {},
   "source": [
    "# Inference on all 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43e2b89d-7c64-4730-9203-445780dc9b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# fold_exp = ['exp26']\n",
    "# test_dir = f'/home/ubuntu/vinbigdata/DemoConversionToJPG/'\n",
    "# os.chdir('/home/ubuntu/vinbigdata/yolov5')\n",
    "\n",
    "\n",
    "# for fold, exp in enumerate(fold_exp):\n",
    "#     weights_dir = f'/home/ubuntu/vinbigdata/yolov5/runs/train/{exp}/weights/best.pt'\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/yolov5/')\n",
    "    \n",
    "#     !python detect.py --weights $weights_dir\\\n",
    "#     --img 1024\\\n",
    "#     --conf 0.1\\\n",
    "#     --iou 0.4\\\n",
    "#     --source $test_dir\\\n",
    "#     --save-txt --save-conf --exist-ok\n",
    "    \n",
    "#     image_ids = []\n",
    "#     PredictionStrings = []\n",
    "\n",
    "#     for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n",
    "#         image_id = file_path.split('/')[-1].split('.')[0]\n",
    "#         # print(image_id)\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns']].values[0])\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0])\n",
    "#         w, h = test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0]\n",
    "#         f = open(file_path, 'r')\n",
    "#         data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "#         data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "#         bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n",
    "#         for idx in range(len(bboxes)):\n",
    "#             bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n",
    "#         image_ids.append(image_id)\n",
    "#         PredictionStrings.append(' '.join(bboxes))\n",
    "\n",
    "#     # credit / source: https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer\n",
    "#     pred_df = pd.DataFrame({'file':image_ids,\n",
    "#                             'PredictionString':PredictionStrings})\n",
    "#     # Needs to be the dataframe with \n",
    "#     df0 = pd.merge(test_df, pred_df, on = 'file', how = 'left').fillna(\"14 1 0 0 1 1\")\n",
    "#     df0 = df0[['file', 'PredictionString']]\n",
    "\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/')\n",
    "\n",
    "#     # remove files and folders from yolov5/runs/detect/exp/\n",
    "#     dir = '/home/ubuntu/vinbigdata/yolov5/runs/detect/exp/'\n",
    "#     for files in os.listdir(dir):\n",
    "#         path = os.path.join(dir, files)\n",
    "#         try:\n",
    "#             shutil.rmtree(path)\n",
    "#         except OSError:\n",
    "#             os.remove(path)\n",
    "\n",
    "# fold_exp = ['exp27']\n",
    "# test_dir = f'/home/ubuntu/vinbigdata/DemoConversionToJPG/'\n",
    "# os.chdir('/home/ubuntu/vinbigdata/yolov5')\n",
    "\n",
    "\n",
    "# for fold, exp in enumerate(fold_exp):\n",
    "#     weights_dir = f'/home/ubuntu/vinbigdata/yolov5/runs/train/{exp}/weights/best.pt'\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/yolov5/')\n",
    "    \n",
    "#     !python detect.py --weights $weights_dir\\\n",
    "#     --img 1024\\\n",
    "#     --conf 0.1\\\n",
    "#     --iou 0.4\\\n",
    "#     --source $test_dir\\\n",
    "#     --save-txt --save-conf --exist-ok\n",
    "    \n",
    "#     image_ids = []\n",
    "#     PredictionStrings = []\n",
    "\n",
    "#     for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n",
    "#         image_id = file_path.split('/')[-1].split('.')[0]\n",
    "#         # print(image_id)\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns']].values[0])\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0])\n",
    "#         w, h = test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0]\n",
    "#         f = open(file_path, 'r')\n",
    "#         data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "#         data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "#         bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n",
    "#         for idx in range(len(bboxes)):\n",
    "#             bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n",
    "#         image_ids.append(image_id)\n",
    "#         PredictionStrings.append(' '.join(bboxes))\n",
    "\n",
    "#     # credit / source: https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer\n",
    "#     pred_df = pd.DataFrame({'file':image_ids,\n",
    "#                             'PredictionString':PredictionStrings})\n",
    "#     # Needs to be the dataframe with \n",
    "#     df1 = pd.merge(test_df, pred_df, on = 'file', how = 'left').fillna(\"14 1 0 0 1 1\")\n",
    "#     df1 = df1[['file', 'PredictionString']]\n",
    "\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/')\n",
    "\n",
    "#     # remove files and folders from yolov5/runs/detect/exp/\n",
    "#     dir = '/home/ubuntu/vinbigdata/yolov5/runs/detect/exp/'\n",
    "#     for files in os.listdir(dir):\n",
    "#         path = os.path.join(dir, files)\n",
    "#         try:\n",
    "#             shutil.rmtree(path)\n",
    "#         except OSError:\n",
    "#             os.remove(path)\n",
    "            \n",
    "# fold_exp = ['exp28']\n",
    "# test_dir = f'/home/ubuntu/vinbigdata/DemoConversionToJPG/'\n",
    "# os.chdir('/home/ubuntu/vinbigdata/yolov5')\n",
    "\n",
    "\n",
    "# for fold, exp in enumerate(fold_exp):\n",
    "#     weights_dir = f'/home/ubuntu/vinbigdata/yolov5/runs/train/{exp}/weights/best.pt'\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/yolov5/')\n",
    "    \n",
    "#     !python detect.py --weights $weights_dir\\\n",
    "#     --img 1024\\\n",
    "#     --conf 0.1\\\n",
    "#     --iou 0.4\\\n",
    "#     --source $test_dir\\\n",
    "#     --save-txt --save-conf --exist-ok\n",
    "    \n",
    "#     image_ids = []\n",
    "#     PredictionStrings = []\n",
    "\n",
    "#     for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n",
    "#         image_id = file_path.split('/')[-1].split('.')[0]\n",
    "#         # print(image_id)\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns']].values[0])\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0])\n",
    "#         w, h = test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0]\n",
    "#         f = open(file_path, 'r')\n",
    "#         data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "#         data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "#         bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n",
    "#         for idx in range(len(bboxes)):\n",
    "#             bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n",
    "#         image_ids.append(image_id)\n",
    "#         PredictionStrings.append(' '.join(bboxes))\n",
    "\n",
    "#     # credit / source: https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer\n",
    "#     pred_df = pd.DataFrame({'file':image_ids,\n",
    "#                             'PredictionString':PredictionStrings})\n",
    "#     # Needs to be the dataframe with \n",
    "#     df2 = pd.merge(test_df, pred_df, on = 'file', how = 'left').fillna(\"14 1 0 0 1 1\")\n",
    "#     df2 = df2[['file', 'PredictionString']]\n",
    "\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/')\n",
    "\n",
    "#     # remove files and folders from yolov5/runs/detect/exp/\n",
    "#     dir = '/home/ubuntu/vinbigdata/yolov5/runs/detect/exp/'\n",
    "#     for files in os.listdir(dir):\n",
    "#         path = os.path.join(dir, files)\n",
    "#         try:\n",
    "#             shutil.rmtree(path)\n",
    "#         except OSError:\n",
    "#             os.remove(path)            \n",
    "\n",
    "# fold_exp = ['exp29']\n",
    "# test_dir = f'/home/ubuntu/vinbigdata/DemoConversionToJPG/'\n",
    "# os.chdir('/home/ubuntu/vinbigdata/yolov5')\n",
    "\n",
    "\n",
    "# for fold, exp in enumerate(fold_exp):\n",
    "#     weights_dir = f'/home/ubuntu/vinbigdata/yolov5/runs/train/{exp}/weights/best.pt'\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/yolov5/')\n",
    "    \n",
    "#     !python detect.py --weights $weights_dir\\\n",
    "#     --img 1024\\\n",
    "#     --conf 0.1\\\n",
    "#     --iou 0.4\\\n",
    "#     --source $test_dir\\\n",
    "#     --save-txt --save-conf --exist-ok\n",
    "    \n",
    "#     image_ids = []\n",
    "#     PredictionStrings = []\n",
    "\n",
    "#     for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n",
    "#         image_id = file_path.split('/')[-1].split('.')[0]\n",
    "#         # print(image_id)\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns']].values[0])\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0])\n",
    "#         w, h = test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0]\n",
    "#         f = open(file_path, 'r')\n",
    "#         data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "#         data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "#         bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n",
    "#         for idx in range(len(bboxes)):\n",
    "#             bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n",
    "#         image_ids.append(image_id)\n",
    "#         PredictionStrings.append(' '.join(bboxes))\n",
    "\n",
    "#     # credit / source: https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer\n",
    "#     pred_df = pd.DataFrame({'file':image_ids,\n",
    "#                             'PredictionString':PredictionStrings})\n",
    "#     # Needs to be the dataframe with \n",
    "#     df3 = pd.merge(test_df, pred_df, on = 'file', how = 'left').fillna(\"14 1 0 0 1 1\")\n",
    "#     df3 = df3[['file', 'PredictionString']]\n",
    "\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/')\n",
    "\n",
    "#     # remove files and folders from yolov5/runs/detect/exp/\n",
    "#     dir = '/home/ubuntu/vinbigdata/yolov5/runs/detect/exp/'\n",
    "#     for files in os.listdir(dir):\n",
    "#         path = os.path.join(dir, files)\n",
    "#         try:\n",
    "#             shutil.rmtree(path)\n",
    "#         except OSError:\n",
    "#             os.remove(path)\n",
    "            \n",
    "# fold_exp = ['exp30']\n",
    "# test_dir = f'/home/ubuntu/vinbigdata/DemoConversionToJPG/'\n",
    "# os.chdir('/home/ubuntu/vinbigdata/yolov5')\n",
    "\n",
    "\n",
    "# for fold, exp in enumerate(fold_exp):\n",
    "#     weights_dir = f'/home/ubuntu/vinbigdata/yolov5/runs/train/{exp}/weights/best.pt'\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/yolov5/')\n",
    "    \n",
    "#     !python detect.py --weights $weights_dir\\\n",
    "#     --img 1024\\\n",
    "#     --conf 0.1\\\n",
    "#     --iou 0.4\\\n",
    "#     --source $test_dir\\\n",
    "#     --save-txt --save-conf --exist-ok\n",
    "    \n",
    "#     image_ids = []\n",
    "#     PredictionStrings = []\n",
    "\n",
    "#     for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n",
    "#         image_id = file_path.split('/')[-1].split('.')[0]\n",
    "#         # print(image_id)\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns']].values[0])\n",
    "#         # print(test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0])\n",
    "#         w, h = test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0]\n",
    "#         f = open(file_path, 'r')\n",
    "#         data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "#         data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "#         bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n",
    "#         for idx in range(len(bboxes)):\n",
    "#             bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n",
    "#         image_ids.append(image_id)\n",
    "#         PredictionStrings.append(' '.join(bboxes))\n",
    "\n",
    "#     # credit / source: https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer\n",
    "#     pred_df = pd.DataFrame({'file':image_ids,\n",
    "#                             'PredictionString':PredictionStrings})\n",
    "#     # Needs to be the dataframe with \n",
    "#     df4 = pd.merge(test_df, pred_df, on = 'file', how = 'left').fillna(\"14 1 0 0 1 1\")\n",
    "#     df4 = df4[['file', 'PredictionString']]\n",
    "\n",
    "#     os.chdir('/home/ubuntu/vinbigdata/')\n",
    "\n",
    "#     # remove files and folders from yolov5/runs/detect/exp/\n",
    "#     dir = '/home/ubuntu/vinbigdata/yolov5/runs/detect/exp/'\n",
    "#     for files in os.listdir(dir):\n",
    "#         path = os.path.join(dir, files)\n",
    "#         try:\n",
    "#             shutil.rmtree(path)\n",
    "#         except OSError:\n",
    "#             os.remove(path)\n",
    "            \n",
    "\n",
    "# #Lists for storing each frame of the files\n",
    "\n",
    "# final_list=[]\n",
    "# input_file_data0=[]\n",
    "# input_file_data1=[]\n",
    "# input_file_data2=[]\n",
    "# input_file_data3=[]\n",
    "# input_file_data4=[]\n",
    "\n",
    "# # Process the lists from each of the csvs frame by frame.\n",
    "\n",
    "# for i in range(len(df0)):    \n",
    "#     #File 0\n",
    "#     a= df0.iloc[i,:]\n",
    "#     tmp0=a[1]\n",
    "#     tmp0=tmp0.split()\n",
    "    \n",
    "#     # File 1\n",
    "#     a1= df1.iloc[i,:]\n",
    "#     tmp1=a1[1]\n",
    "#     tmp1=tmp1.split()\n",
    "            \n",
    "#     # File 2\n",
    "#     a2= df2.iloc[i,:]\n",
    "#     tmp2=a2[1]\n",
    "#     tmp2=tmp2.split()\n",
    "        \n",
    "#     # File 3\n",
    "#     a3= df3.iloc[i,:]\n",
    "#     tmp3=a3[1]\n",
    "#     tmp3=tmp3.split()\n",
    "        \n",
    "#     # File 4\n",
    "#     a4= df4.iloc[i,:]\n",
    "#     tmp4=a4[1]\n",
    "#     tmp4=tmp4.split()\n",
    "    \n",
    "# #Convert the frames into specific format of Ensemble function\n",
    "\n",
    "#     for j in range(5): \n",
    "#         globals()['input_file_data%s' % j].append(transform_object(eval('df'+str(j)),eval('tmp'+str(j)),1))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "# #Apply the Ensemble function\n",
    "# df = df0.copy()\n",
    "\n",
    "# for i in tqdm(range(len(df0))):\n",
    "#     final_list=[input_file_data0[i],input_file_data1[i],input_file_data2[i],input_file_data3[i],input_file_data4[i]]\n",
    "#     ens = GeneralEnsemble(final_list,iou_thresh = 0.4)\n",
    "#     lst = []\n",
    "#     for j in ens:\n",
    "#         lst.append(j[4])\n",
    "#         lst.append(j[5])\n",
    "#         lst.append(j[0] - j[2]/2)\n",
    "#         lst.append(j[1] - j[3]/2)\n",
    "#         lst.append(j[0] + j[2]/2)\n",
    "#         lst.append(j[1] + j[3]/2)\n",
    "#     df.iloc[i,1] = lst\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     if row[\"PredictionString\"] == [14, 0.5, 0.0, 0.0, 1.0, 1.0]:\n",
    "#         row[\"PredictionString\"] = [14, 1, 0, 0, 1, 1]\n",
    "        \n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     row[\"PredictionString\"] = ' '.join(str(e) for e in row[\"PredictionString\"])\n",
    "\n",
    "\n",
    "# preds = df['PredictionString'].tolist()\n",
    "# grouped_preds = [list(divide(pred.split(), 6)) for pred in preds]\n",
    "# grouped_preds[:5]\n",
    "\n",
    "# new_preds = []\n",
    "\n",
    "# for pred in grouped_preds:\n",
    "#     temp = ''\n",
    "#     # each box is a tuple of 6 i.e. (class, confidence, xmin, ymin, xmax, ymax)\n",
    "#     for box in pred:\n",
    "#         # if we found some bounding-box i.e. `len(pred) > 1` & class is \"No finding\".\n",
    "#         if len(pred) > 1 and box[0] == '14':\n",
    "#             # Make the probability 0.\n",
    "#             box[1] = '0'\n",
    "#         temp += ' '.join(box) + ' '\n",
    "#     new_preds.append(temp.strip())\n",
    "    \n",
    "# new_preds[:5]\n",
    "\n",
    "# df['PredictionString'] = new_preds\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bda1d36-f1cc-474b-900c-4e97af80350f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>image_height</th>\n",
       "      <th>image_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0403dda5a9bf46457517b604869d530d</td>\n",
       "      <td>14 0 0.0 0.0 1.0 1.0 11 0.06 1266.0 312.0 1509...</td>\n",
       "      <td>2430</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>034b98d64dc012298afb3d33fe880193</td>\n",
       "      <td>14 0 0.0 0.0 1.0 1.0 0 0.02 1249.0 492.0 1507....</td>\n",
       "      <td>2430</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>056815f22ac3de9b9eb6fb963d4cfa5a</td>\n",
       "      <td>14 0 0.0 0.0 1.0 1.0 8 0.02 879.0 1960.0 969.0...</td>\n",
       "      <td>2430</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07229c769cb2c284c1114c6fe7ed3dd6</td>\n",
       "      <td>0 0.5800000000000001 1228.25 805.7499999999999...</td>\n",
       "      <td>3072</td>\n",
       "      <td>2540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03ea976a276b66285825246525357949</td>\n",
       "      <td>11 0.18 835.0 537.4999999999999 985.5 663.4999...</td>\n",
       "      <td>2748</td>\n",
       "      <td>2494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               file  \\\n",
       "0  0403dda5a9bf46457517b604869d530d   \n",
       "1  034b98d64dc012298afb3d33fe880193   \n",
       "2  056815f22ac3de9b9eb6fb963d4cfa5a   \n",
       "3  07229c769cb2c284c1114c6fe7ed3dd6   \n",
       "4  03ea976a276b66285825246525357949   \n",
       "\n",
       "                                    PredictionString  image_height  \\\n",
       "0  14 0 0.0 0.0 1.0 1.0 11 0.06 1266.0 312.0 1509...          2430   \n",
       "1  14 0 0.0 0.0 1.0 1.0 0 0.02 1249.0 492.0 1507....          2430   \n",
       "2  14 0 0.0 0.0 1.0 1.0 8 0.02 879.0 1960.0 969.0...          2430   \n",
       "3  0 0.5800000000000001 1228.25 805.7499999999999...          3072   \n",
       "4  11 0.18 835.0 537.4999999999999 985.5 663.4999...          2748   \n",
       "\n",
       "   image_width  \n",
       "0         1994  \n",
       "1         1994  \n",
       "2         1994  \n",
       "3         2540  \n",
       "4         2494  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734b3b0-1785-4aa8-a917-65113ca213b3",
   "metadata": {},
   "source": [
    "# Send final predictions back to SingleStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9447ebc3-0789-4ecb-abd8-c96b30bd114f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 5.37 ms, total: 33.3 ms\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pymysql\n",
    "\n",
    "s2conn = pymysql.connect(\n",
    "    user='root',\n",
    "    password='Sglstrpw34',\n",
    "    host='172.31.62.112',\n",
    "    port=3306,\n",
    "    database='PatientRecords')\n",
    "\n",
    "for ind in df.index:\n",
    "    InFile = df['file'][ind]\n",
    "    InPredictionString = df['PredictionString'][ind]\n",
    "    mycursor = s2conn.cursor()\n",
    "    sql = \"call InsertImagePredictions('\" + InFile + \"','\" + InPredictionString + \"')\"\n",
    "    mycursor.execute(sql)\n",
    "    s2conn.commit()\n",
    "  \n",
    "mycursor.close()\n",
    "s2conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7d6ea1-1195-487d-bfdb-4a9afd059976",
   "metadata": {},
   "source": [
    "# Switch back to Pytorch_p37 environment and final test display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618ed199-90b3-4ae7-89bc-210e33642908",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d57940b-b9a8-48e1-b59f-17fca33e75fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06875189-b4f5-4bb9-9cf1-939793e0e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 ms, sys: 4.47 ms, total: 22.6 ms\n",
      "Wall time: 139 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sqlalchemy/engine/default.py:410: SAWarning: Exception attempting to detect unicode returns: ProgrammingError('(pymysql.err.ProgrammingError) (1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near \\'CHARACTER SET utf8mb4) COLLATE utf8mb4_bin AS anon_1\\' at line 1\")')\n",
      "  \"detect unicode returns: %r\" % de\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/sqlalchemy/dialects/mysql/reflection.py:62: SAWarning: Unknown schema content: '  , SHARD KEY () '\n",
      "  util.warn(\"Unknown schema content: %r\" % line)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s2conn = create_engine('mysql+pymysql://root:Sglstrpw34@172.31.62.112:3306/PatientRecords')\n",
    "# df.to_sql('ImageHeaderdf', s2conn, if_exists='replace', index = False)\n",
    "df2 = pd.read_sql_table('ImageHeaderdf', s2conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "479ae594-0c0a-448b-899c-327c176d4477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121e650bba0d2537b821fb20bcc0db86</td>\n",
       "      <td>7 0.06000000000000001 249.5 472.5 745.0 1455.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04b68e83e611caf345b0a1dc9c65ec88</td>\n",
       "      <td>11 0.4000000000000001 1703.0000000000002 673.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0c187ebe652499a7e28fd93da2e42ebb</td>\n",
       "      <td>14 0 0.0 0.0 1.0 1.0 3 0.06 878.0 1132.0 1640....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0e8b4d8bb1a8719e9e8f4755f13e34c4</td>\n",
       "      <td>0 0.7000000000000001 1233.3999999999999 771.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0b8ec8f17db23936e86de9ca3f36d206</td>\n",
       "      <td>11 0.04 1191.0 444.0 1467.0 492.0 14 0 0.0 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0271d381c3e88527721efcfaf518be71</td>\n",
       "      <td>3 0.8600000000000001 829.4000000000001 1758.6 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>05e951c63e80999f13e6e09e7ec8439a</td>\n",
       "      <td>11 0.34 1255.3333333333333 93.33333333333331 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0ef99f92d68d16b8912cc073731ffad1</td>\n",
       "      <td>11 0.16 1415.0 447.0 1667.0 506.0 11 0.3200000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0d60b79ab9aee1e4687e17fdc56ead06</td>\n",
       "      <td>0 0.64 1192.4 1180.8000000000002 1662.6 1581.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>07fecb6f57a3d452c4764b1013740141</td>\n",
       "      <td>3 0.8200000000000002 783.8 1330.8 1732.3999999...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file  \\\n",
       "0    121e650bba0d2537b821fb20bcc0db86   \n",
       "1    04b68e83e611caf345b0a1dc9c65ec88   \n",
       "2    0c187ebe652499a7e28fd93da2e42ebb   \n",
       "3    0e8b4d8bb1a8719e9e8f4755f13e34c4   \n",
       "4    0b8ec8f17db23936e86de9ca3f36d206   \n",
       "..                                ...   \n",
       "209  0271d381c3e88527721efcfaf518be71   \n",
       "210  05e951c63e80999f13e6e09e7ec8439a   \n",
       "211  0ef99f92d68d16b8912cc073731ffad1   \n",
       "212  0d60b79ab9aee1e4687e17fdc56ead06   \n",
       "213  07fecb6f57a3d452c4764b1013740141   \n",
       "\n",
       "                                      PredictionString  \n",
       "0    7 0.06000000000000001 249.5 472.5 745.0 1455.0...  \n",
       "1    11 0.4000000000000001 1703.0000000000002 673.9...  \n",
       "2    14 0 0.0 0.0 1.0 1.0 3 0.06 878.0 1132.0 1640....  \n",
       "3    0 0.7000000000000001 1233.3999999999999 771.19...  \n",
       "4    11 0.04 1191.0 444.0 1467.0 492.0 14 0 0.0 0.0...  \n",
       "..                                                 ...  \n",
       "209  3 0.8600000000000001 829.4000000000001 1758.6 ...  \n",
       "210  11 0.34 1255.3333333333333 93.33333333333331 1...  \n",
       "211  11 0.16 1415.0 447.0 1667.0 506.0 11 0.3200000...  \n",
       "212  0 0.64 1192.4 1180.8000000000002 1662.6 1581.0...  \n",
       "213  3 0.8200000000000002 783.8 1330.8 1732.3999999...  \n",
       "\n",
       "[214 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25ef3bf6-0dea-4b25-bec8-8407f60d389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a Dicom Image\n",
    "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    \n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "               \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "        \n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31ed3207-84d0-46fc-ac3b-9e76402e4ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pydicom' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-6f1c50fafbe8>\u001b[0m in \u001b[0;36mread_xray\u001b[0;34m(path, voi_lut, fix_monochrome)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read a Dicom Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_xray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoi_lut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_monochrome\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdicom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pydicom' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "img = read_xray('train/0108949daa13dc94634a7d650a05c0bb.dicom')\n",
    "plt.figure(figsize = (12,12))\n",
    "plt.imshow(img, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e233c-2512-456d-887c-09a812cdaf4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9735114-6985-4363-88fc-6979e9b42285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db8b5842-8f68-4bdb-aa1b-16f07e9f5ce9",
   "metadata": {},
   "source": [
    "# Send to S2 (Ian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c0980-613d-454f-8713-04cfbb1dd045",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2conn = pymysql.connect(\n",
    "    user='root',\n",
    "    password='Sglstrpw34',\n",
    "    host='172.31.62.112',\n",
    "    port=3306,\n",
    "    database='PatientRecords')\n",
    "\n",
    "mycursor = s2conn.cursor()\n",
    "\n",
    "sql = \"select ImageID, ClassName, ClassID, RadiologestID, XMin, YMin, XMax, YMax from ImageTraining\"\n",
    "\n",
    "mycursor.execute(sql)\n",
    "\n",
    "train = pd.DataFrame(mycursor.fetchall(), columns = ['image_id','class_name','class_id','rad_id','x_min','y_min','x_max','y_max'])\n",
    "\n",
    "mycursor.close()\n",
    "s2conn.close()\n",
    "train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dd206a-b429-4a99-9bc4-867e55c1a9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eccbe8a-4f2e-41fc-93f4-152ee7c7e89a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VA4",
   "language": "python",
   "name": "va4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
