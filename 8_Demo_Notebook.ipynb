{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d007662b-93d4-4253-a029-0c322c65243c",
   "metadata": {},
   "source": [
    "# Veteran Affairs & SingleStore - Detecting Anomalies in Chest X-rays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53ed0e-7705-4fdf-8325-eca3d8a30f7d",
   "metadata": {},
   "source": [
    "### Improving healthcare efficiency through Computer Vision and near real time analytics with SingleStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99598be5-0092-41c0-99d6-77eca020389e",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/1st_image.png\" width=\"600\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc68aa2-669e-480e-9110-16e4817638b1",
   "metadata": {},
   "source": [
    "<a name=\"contents\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa77acd-949d-49bd-9a46-862ae7fe5cac",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedcd3d0-b82b-44f4-87c4-41d009c4c63f",
   "metadata": {},
   "source": [
    "- [Overview](#overview)\n",
    "- [Dataset Information](#dataset)\n",
    "- [Send Headers and JPG to SingleStore](#send_to_s2)\n",
    "- [About the Trained Model](#about_model)\n",
    "- [Timed Demo](#timed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8434f431-1f7f-4133-9232-65877f1eae4c",
   "metadata": {},
   "source": [
    "<a name=\"overview\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76442e2b-e995-4222-b1e4-8be4301df75d",
   "metadata": {},
   "source": [
    "- [Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc90e98-ab23-4069-bd0b-e5714d288639",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f9ae3-88b4-418b-9d0a-937528bcf4a8",
   "metadata": {},
   "source": [
    "### General Radiology overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b17ad04-510d-444e-95c1-38aa27ff9318",
   "metadata": {},
   "source": [
    " - There are 9,992 Diagnostic Imaging Centers Businesses in the US in 2021  \n",
    "source: https://www.ibisworld.com/industry-statistics/number-of-businesses/diagnostic-imaging-centers-united-states/   \n",
    "\n",
    "- The US has approximately 30,000 post-training, professionally active radiologists, or about 100 radiologists per million Americans.  \n",
    "source: https://answerstoall.com/common-questions/how-many-radiologists-are-in-the-us-in-2021/  \n",
    "\n",
    "- Worldwide, an estimated 3.6 billion diagnostic medical examinations, such as X-rays, are performed every year.  source: https://www.who.int/news-room/feature-stories/detail/to-x-ray-or-not-to-x-ray-\n",
    "\n",
    "- Chest X-rays are used for diagnosis\n",
    "- Two views: The back and side\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c250f-2564-4f37-b1cd-52d8fba53088",
   "metadata": {},
   "source": [
    "### The problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e334d91-665d-448c-936d-79301398267d",
   "metadata": {},
   "source": [
    "- Chest X-rays are critical for the detection of acute thoracic diseases affecting millions of people worldwide each year.\n",
    "- Fatigue based diagnostic error and lack of expertise in areas where radiologists are not available\n",
    "\n",
    "- Americaâ€™s shortage of radiologists and other physician specialists could surpass 35,000 by 2034  \n",
    "source: https://www.radiologybusiness.com/topics/artificial-intelligence/physician-shortages-radiology-aamc-artificial-intelligence \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae28a7-f8de-40ef-8e5f-4274cfc86531",
   "metadata": {},
   "source": [
    "### Solutions:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c78967-9e6d-4cd6-bb9a-2b438166f144",
   "metadata": {},
   "source": [
    "- New research opportunities\n",
    "- Decision Support. \n",
    "- Speed and scale\n",
    "- Determine the levels of urgency and relevancy faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa3febe-6e23-4239-848a-9454783db58e",
   "metadata": {},
   "source": [
    "<a name=\"dataset\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3bf3dd-fa58-4aa8-9991-8888ad0ee051",
   "metadata": {},
   "source": [
    "- [Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eba4ba-2c6a-4c7e-bed0-6d1d3bd3f1e9",
   "metadata": {},
   "source": [
    "# Vinbigdata Dicom header information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6331f-7c66-4368-89c7-bf8ac1f6b41f",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/dataset_statistics.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e87d96d-bebc-46bd-b9c3-a7e3f842fa24",
   "metadata": {},
   "source": [
    "# Patient Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c35ca-938d-4b86-86b7-1da364b04d4f",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/patient_gender.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c650e57-31ad-40bf-8757-677bf6ddad08",
   "metadata": {},
   "source": [
    "# Patient Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa0130d-67e5-4d33-8599-d61e380d34ec",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/patient_age.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441e661-d45a-4e96-985b-d4505dc91e35",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/dicom_missing_values_chart.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2e1a9-34f1-42fc-96b9-9fc10753ec47",
   "metadata": {},
   "source": [
    "<a name=\"about_model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9862d50-0352-4eb3-861c-7bb5ad57d4c4",
   "metadata": {},
   "source": [
    "- [Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72cce66-d7dc-48d0-99dd-c7d90f145e39",
   "metadata": {},
   "source": [
    "# About the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a2c070-c7e7-4462-b26f-acc4ec04ad23",
   "metadata": {},
   "source": [
    "## 5 K-fold ensemble model using Yolov5 Architecture and transfer learning with pre-trained wieghts\n",
    "- 60 Epochs\n",
    "- Using 15000 Train Files split into 5 parts\n",
    "- Each Fold is 444 layers\n",
    "- 86,260,891 parameters\n",
    "- Using an Ensemble approach should improve model prediction generalizations, resulting in a more accurate model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcfc149-567a-4a7a-9cc3-9f9afff52662",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/train_obj_loss.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ecb721-5005-43c0-aa58-21aea6ae3a9c",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/mean_avg_precision_.5.png\" width=\"700\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c61e6b-862b-4e75-a1d7-d547dbc33044",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/confusion_matrix.png\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54af2f14-4d3e-4a8a-8da0-11ed1ac27642",
   "metadata": {},
   "source": [
    "## Training mosaics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a65ba-a3ad-4dc8-8288-03c5fedc0c45",
   "metadata": {},
   "source": [
    "![](assets/train_mosaics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04d3673-7b28-4dc0-8451-be4bac85c7b1",
   "metadata": {},
   "source": [
    "<a name=\"timed\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a863e86-cfe3-40de-89ad-24020b6d89a2",
   "metadata": {},
   "source": [
    "- [Back to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ee36e-0248-45c8-bbdb-ca9a6ac834ee",
   "metadata": {},
   "source": [
    "# Timed Example with 11 Dicom Image (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d57dd399-2baf-4083-9e25-01e8466cac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.2 s, sys: 692 ms, total: 2.9 s\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# !pip install pydicom\n",
    "# !pip install kornia\n",
    "# !pip install PyMySQL\n",
    "# !pip install SQLAlchemy\n",
    "from pathlib import Path\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import tqdm\n",
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from fastai.medical.imaging import *\n",
    "from fastai.vision.all import *\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as ptc\n",
    "from tqdm import tqdm # for getting a progress bar on loops\n",
    "# import pymysql\n",
    "import time\n",
    "from PIL import Image\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "# Functions\n",
    "\n",
    "# Read a Dicom Image\n",
    "def read_xray(path, voi_lut = True, fix_monochrome = True):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    \n",
    "    # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to \"human-friendly\" view\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "               \n",
    "    # depending on this value, X-ray may look inverted - fix that:\n",
    "    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "        data = np.amax(data) - data\n",
    "        \n",
    "    data = data - np.min(data)\n",
    "    data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "        \n",
    "    return data\n",
    "\n",
    "def get_dcm_contents(file):\n",
    "    dcm = Path(f_path + file).dcmread()    \n",
    "    properties = [string for string in dir(dcm) if prog.match(string).group(0)!='']\n",
    "    dict1 = {'file': file.replace('.dicom', '')}    \n",
    "    dict1.update( { what: dcm[what].value for what in properties if isinstance(dcm[what].value, (bytes, bytearray))!=True } )\n",
    "    return dict1\n",
    "\n",
    "\n",
    "# Convert to JPG and resize to max 1024 pixels\n",
    "def resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h,w) = image.shape[:2]\n",
    "    \n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    \n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w*r), height)\n",
    "        \n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h*r))\n",
    "    \n",
    "    # resize image\n",
    "    img = cv2.resize(image, dim, interpolation=inter)\n",
    "    \n",
    "    # return the resized image\n",
    "    return img\n",
    "\n",
    "def convertToBinaryData(ImageFile):\n",
    "    # Convert digital data to binary format\n",
    "    with open(ImageFile, 'rb') as file:\n",
    "        binaryData = file.read()\n",
    "    return binaryData\n",
    "\n",
    "\n",
    "def insertBLOB(ImageID, ImagePath, ImageFile):\n",
    "    #print(\"Inserting BLOB into JPGImages table\")\n",
    "    mycursor = s2conn.cursor()\n",
    "\n",
    "    sql_insert_blob_query = \"\"\" INSERT IGNORE INTO JPGImages\n",
    "                      (file, ImagePath, Image) VALUES (%s,%s,%s)\"\"\"\n",
    "\n",
    "    jpgImage = convertToBinaryData(ImageFile)\n",
    "\n",
    "    # Convert data into tuple format\n",
    "    insert_blob_tuple = (ImageID, ImagePath, jpgImage)\n",
    "    result = mycursor.execute(sql_insert_blob_query, insert_blob_tuple)\n",
    "    s2conn.commit()\n",
    "    mycursor.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deaa577d-7f94-40f9-920a-550b9b3b3204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:04<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of val_jpg_test files in 11DemoConversionToJPG/: 11\n",
      "Inserted 11 images\n",
      "Time it took for DICOM metadata and JPG images to reach SingleStore: 0.35 seconds\n",
      "CPU times: user 3.67 s, sys: 1.19 s, total: 4.87 s\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create list of every file in the Dicom folder\n",
    "\n",
    "f_path = '11DemoDicomImage/'\n",
    "files = [f for f in os.listdir(f_path) if os.path.isfile(os.path.join(f_path, f))]\n",
    "prog = re.compile('^[A-Z]*')\n",
    "\n",
    "\n",
    "# Extract the Dicom Metadata from the file list\n",
    "\n",
    "\n",
    "df = pd.DataFrame( [ get_dcm_contents(file) for file in files ] )\n",
    "\n",
    "val_outdir = '11DemoConversionToJPG/'\n",
    "\n",
    "for files in os.listdir(val_outdir):\n",
    "    path = os.path.join(val_outdir, files)\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except OSError:\n",
    "        os.remove(path)\n",
    "\n",
    "if not os.path.exists(val_outdir):\n",
    "    os.mkdir(val_outdir)\n",
    "\n",
    "    \n",
    "# Resizing DICOM image and converting to JPG\n",
    "\n",
    "\n",
    "val_list = [os.path.basename(x) for x in glob.glob(f_path + './*.dicom')]\n",
    "for f in tqdm(val_list):  \n",
    "    if not os.path.exists(f_path + f[:-5] + 'jpg'):\n",
    "        img = read_xray(f_path + f) # read dicom image\n",
    "        img = resize(img,height=1024)\n",
    "        cv2.imwrite(val_outdir + f.replace('.dicom','.jpg'),img) # write jpg image\n",
    "        \n",
    "val_jpg_files = glob.glob(f'{val_outdir}/*.jpg')\n",
    "print (f'Number of val_jpg_test files in {val_outdir}: {len(val_jpg_files)}')\n",
    "\n",
    "\n",
    "# Send Dicom metadata to SingleStore, started timer.\n",
    "\n",
    "\n",
    "startTime = time.time()\n",
    "s2conn = create_engine('mysql+pymysql://root:Sglstrpw34@172.31.62.112:3306/PatientRecords')\n",
    "df.to_sql('ImageHeaderdf', s2conn, if_exists='replace', index = False)\n",
    "\n",
    "\n",
    "# Send Resized JPG Images to SingleStore\n",
    "\n",
    "\n",
    "directory = '/home/ubuntu/vinbigdata/11DemoConversionToJPG/'\n",
    "jpgCount = 0\n",
    "\n",
    "s2conn = pymysql.connect(\n",
    "    user='root',\n",
    "    password='Sglstrpw34',\n",
    "    host='172.31.62.112',\n",
    "    port=3306,\n",
    "    database='Images')\n",
    "\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        file = os.path.splitext(os.path.basename(os.path.basename(f)))[0]\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f) and f.endswith(\".jpg\"):\n",
    "            insertBLOB(file, directory, f)\n",
    "            jpgCount += 1\n",
    "            if jpgCount % 100 == 0:\n",
    "                print (jpgCount, \" Elapse Time\", (datetime.now() - startTime))\n",
    "s2conn.close()\n",
    "\n",
    "\n",
    "# End timer\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "print(f\"Inserted {jpgCount} images\")\n",
    "print(f'Time it took for DICOM metadata and JPG images to reach SingleStore: {round((endTime - startTime),2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6232dbce-a90e-4344-be51-4d2337ace40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55592d1a-8392-49a2-949a-d5a7f840406b",
   "metadata": {},
   "source": [
    "- [Back to Contents](#contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p37)",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
