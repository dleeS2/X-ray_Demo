{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c84bff-1d15-42c7-a7c6-b35938f014bb",
   "metadata": {},
   "source": [
    "# Model Inference on Validation images (env = Conda_Anaconda3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3bb85-b97a-4a5f-b445-7982b695de38",
   "metadata": {},
   "source": [
    "<a name=\"contents2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a0ff31-f2b4-4986-abb2-c262c28706aa",
   "metadata": {},
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234e817-69c9-4d18-bddc-004ca6930348",
   "metadata": {},
   "source": [
    "- [Imports and Functions](#imports2)\n",
    "- [Model Inference & Send to SingleStore](#inference2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b54aa-8831-408a-97a8-f2d24cf6a9e0",
   "metadata": {},
   "source": [
    "<a name=\"imports2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3ac6c-2702-467d-bcf8-cd1562a702d8",
   "metadata": {},
   "source": [
    "- [Back to Contents](#contents2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb04b14-a912-4fdb-9c63-e7c6c5b5438b",
   "metadata": {},
   "source": [
    "# Example with 11 Dicom Image (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82312586-bc90-4c86-bcb2-87f8f1765e7f",
   "metadata": {},
   "source": [
    "## Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39900009-5d9a-43ea-bf4e-e5a05ca4e815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 139 ms, total: 1.54 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Imports\n",
    "# !pip install PyMySQL\n",
    "# !pip install torchvision\n",
    "import numpy as np, pandas as pd\n",
    "from glob import glob\n",
    "import shutil, os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.notebook import tqdm\n",
    "import seaborn as sns\n",
    "import os\n",
    "import torch\n",
    "from IPython.display import Image, clear_output\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Model format conversion\n",
    "def yolo2voc(image_height, image_width, bboxes):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "    \n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "    \n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "# Functions\n",
    "def GeneralEnsemble(dets, iou_thresh = 0.5, weights=None):\n",
    "    assert(type(iou_thresh) == float)\n",
    "    \n",
    "    ndets = len(dets)\n",
    "    \n",
    "    if weights is None:\n",
    "        w = 1/float(ndets)\n",
    "        weights = [w]*ndets\n",
    "    else:\n",
    "        assert(len(weights) == ndets)\n",
    "        \n",
    "        s = sum(weights)\n",
    "        for i in range(0, len(weights)):\n",
    "            weights[i] /= s\n",
    "\n",
    "    out = list()\n",
    "    used = list()\n",
    "    \n",
    "    for idet in range(0,ndets):\n",
    "        det = dets[idet]\n",
    "        for box in det:\n",
    "            if box in used:\n",
    "                continue\n",
    "                \n",
    "            used.append(box)\n",
    "            # Search the other detectors for overlapping box of same class\n",
    "            found = []\n",
    "            for iodet in range(0, ndets):\n",
    "                odet = dets[iodet]\n",
    "                \n",
    "                if odet == det:\n",
    "                    continue\n",
    "                \n",
    "                bestbox = None\n",
    "                bestiou = iou_thresh\n",
    "                for obox in odet:\n",
    "                    if not obox in used:\n",
    "                        # Not already used\n",
    "                        if box[4] == obox[4]:\n",
    "                            # Same class\n",
    "                            iou = computeIOU(box, obox)\n",
    "                            if iou > bestiou:\n",
    "                                bestiou = iou\n",
    "                                bestbox = obox\n",
    "                                \n",
    "                if not bestbox is None:\n",
    "                    w = weights[iodet]\n",
    "                    found.append((bestbox,w))\n",
    "                    used.append(bestbox)\n",
    "                            \n",
    "            # Now we've gone through all other detectors\n",
    "            if len(found) == 0:\n",
    "                new_box = list(box)\n",
    "                new_box[5] /= ndets\n",
    "                out.append(new_box)\n",
    "            else:\n",
    "                allboxes = [(box, weights[idet])]\n",
    "                allboxes.extend(found)\n",
    "                \n",
    "                xc = 0.0\n",
    "                yc = 0.0\n",
    "                bw = 0.0\n",
    "                bh = 0.0\n",
    "                conf = 0.0\n",
    "                \n",
    "                wsum = 0.0\n",
    "                for bb in allboxes:\n",
    "                    w = bb[1]\n",
    "                    wsum += w\n",
    "\n",
    "                    b = bb[0]\n",
    "                    xc += w*b[0]\n",
    "                    yc += w*b[1]\n",
    "                    bw += w*b[2]\n",
    "                    bh += w*b[3]\n",
    "                    conf += w*b[5]\n",
    "                    #print(f\"conf = {conf}\")\n",
    "                \n",
    "                xc /= wsum\n",
    "                yc /= wsum\n",
    "                bw /= wsum\n",
    "                bh /= wsum    \n",
    "\n",
    "                new_box = [xc, yc, bw, bh, box[4], conf]\n",
    "                out.append(new_box)\n",
    "    return out\n",
    "    \n",
    "def getCoords(box):\n",
    "    x1 = float(box[0]) - float(box[2])/2\n",
    "    x2 = float(box[0]) + float(box[2])/2\n",
    "    y1 = float(box[1]) - float(box[3])/2\n",
    "    y2 = float(box[1]) + float(box[3])/2\n",
    "    return x1, x2, y1, y2\n",
    "    \n",
    "def computeIOU(box1, box2):\n",
    "    x11, x12, y11, y12 = getCoords(box1)\n",
    "    x21, x22, y21, y22 = getCoords(box2)\n",
    "    \n",
    "    x_left   = max(x11, x21)\n",
    "    y_top    = max(y11, y21)\n",
    "    x_right  = min(x12, x22)\n",
    "    y_bottom = min(y12, y22)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0    \n",
    "        \n",
    "    intersect_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "    box1_area = (x12 - x11) * (y12 - y11)\n",
    "    box2_area = (x22 - x21) * (y22 - y21)        \n",
    "    \n",
    "    iou = intersect_area / (box1_area + box2_area - intersect_area)\n",
    "    return iou\n",
    "\n",
    "# Function to transform the YOLOV5 output to the format the Ensemble function expects. \n",
    "\n",
    "def transform_object(df,tmp,flag):\n",
    "    list_of_floats=[]\n",
    "    for item in tmp:\n",
    "        list_of_floats.append(float(item))\n",
    "        \n",
    "    tm=int(len(list_of_floats)/6)\n",
    "    list1=[]\n",
    "    list2=[]\n",
    "    checkobj=[]\n",
    "    for i in range(tm):\n",
    "          \n",
    "        j=i*6\n",
    "        k=j\n",
    "        l=k+6\n",
    "            \n",
    "        checkobj.append(k)\n",
    "        xmin=list_of_floats[k+2]\n",
    "        ymin=list_of_floats[k+3]\n",
    "        xmax=list_of_floats[k+4]\n",
    "        ymax=list_of_floats[k+5]\n",
    "            \n",
    "        box_w=xmax-xmin\n",
    "        box_h=ymax-ymin\n",
    "        box_x=xmin+(box_w/2)\n",
    "        box_y=ymin+box_h/2\n",
    "            \n",
    "        list1=[box_x,box_y,box_w,box_h,int(list_of_floats[k]),list_of_floats[k+1]]\n",
    "        \n",
    "        list2.append(list1)        \n",
    "        list1=[]\n",
    "    if flag==0:\n",
    "        return checkobj\n",
    "    else:\n",
    "        return list2\n",
    "    \n",
    "#https://www.kaggle.com/prashantkikani/vinbigdata-ensemble-post-processing?scriptVersionId=56245340\n",
    "\n",
    "def divide(l, n):\n",
    "    '''\n",
    "    divide submission string into group of 6\n",
    "    '''\n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n]\n",
    "\n",
    "def convertToBinaryData(ImageFile):\n",
    "    # Convert digital data to binary format\n",
    "    with open(ImageFile, 'rb') as file:\n",
    "        binaryData = file.read()\n",
    "    return binaryData\n",
    "\n",
    "\n",
    "def updateBLOB(ImageID, ImagePath, ImageFile):\n",
    "    #print(\"Inserting BLOB into JPGImages table\")\n",
    "    # try:\n",
    "    mycursor = s2conn.cursor()\n",
    "\n",
    "    sql_update_blob_query = \"\"\" Update JPGImages \n",
    "                        set PredictionImage = %s \n",
    "                        where file = %s \"\"\"\n",
    "\n",
    "    jpgImage = convertToBinaryData(ImageFile)\n",
    "\n",
    "    # Convert data into tuple format\n",
    "    insert_blob_tuple = (jpgImage, ImageID)\n",
    "    result = mycursor.execute(sql_update_blob_query, insert_blob_tuple)\n",
    "    s2conn.commit()\n",
    "    mycursor.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df98f36-8d0a-4ef9-85f2-eb4d4c76c778",
   "metadata": {},
   "source": [
    "<a name=\"inference2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7cd7d-8269-42a3-b3f8-ee9d80fd9cff",
   "metadata": {},
   "source": [
    "- [Back to Contents](#contents2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5086c5fb-077f-4c94-984b-4437e821b8f1",
   "metadata": {},
   "source": [
    "# Ensemble Model Inference and Send Results to SingleStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f556bc30-2c4a-4b42-b1eb-17c5a7c18cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/home/ubuntu/vinbigdata/yolov5/runs/train/exp26/weights/best.pt', '/home/ubuntu/vinbigdata/yolov5/runs/train/exp27/weights/best.pt', '/home/ubuntu/vinbigdata/yolov5/runs/train/exp28/weights/best.pt', '/home/ubuntu/vinbigdata/yolov5/runs/train/exp29/weights/best.pt', '/home/ubuntu/vinbigdata/yolov5/runs/train/exp30/weights/best.pt'], source=/home/ubuntu/vinbigdata/11DemoConversionToJPG/, imgsz=[1024, 1024], conf_thres=0.2, iou_thres=0.4, max_det=1000, device=, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v6.0-115-gbc48457 torch 1.10.0+cu102 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86260891 parameters, 0 gradients\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86260891 parameters, 0 gradients\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86260891 parameters, 0 gradients\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86260891 parameters, 0 gradients\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86260891 parameters, 0 gradients\n",
      "Ensemble created with ['/home/ubuntu/vinbigdata/yolov5/runs/train/exp26/weights/best.pt', '/home/ubuntu/vinbigdata/yolov5/runs/train/exp27/weights/best.pt', '/home/ubuntu/vinbigdata/yolov5/runs/train/exp28/weights/best.pt', '/home/ubuntu/vinbigdata/yolov5/runs/train/exp29/weights/best.pt', '/home/ubuntu/vinbigdata/yolov5/runs/train/exp30/weights/best.pt']\n",
      "\n",
      "image 1/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0168eb925aa6f28a78b16134792f5d0e.jpg: 1024x864 1 Consolidation, 1 Pneumothorax, Done. (0.186s)\n",
      "image 2/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/043111cdad4d26204503d3396876046f.jpg: 1024x1024 1 Consolidation, 1 Pneumothorax, 1 ILD, Done. (0.188s)\n",
      "image 3/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c15e19c74ef8ddd9bed0a4fc7f4b5a8.jpg: 1024x864 1 Aortic enlargement, 1 Pneumothorax, Done. (0.180s)\n",
      "image 4/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c187ebe652499a7e28fd93da2e42ebb.jpg: 1024x864 1 Other lesion, Done. (0.171s)\n",
      "image 5/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c26e997c79d2a3149cf1a62c9444554.jpg: 1024x1024 1 Pneumothorax, Done. (0.188s)\n",
      "image 6/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c5bc5fdf756d1251e431c9281349376.jpg: 1024x864 1 Pneumothorax, Done. (0.180s)\n",
      "image 7/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c6036df3708fe77c1c76498240d6774.jpg: 1024x864 1 Atelectasis, 1 Pleural effusion, 1 Other lesion, 1 Infiltration, Done. (0.171s)\n",
      "image 8/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c6f7b76bcc012fc5a9af4470f735aba.jpg: 1024x896 1 Atelectasis, 1 Nodule/Mass, 1 Pneumothorax, Done. (0.182s)\n",
      "image 9/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c785dff51447d6e689e15dcfe10c8e2.jpg: 1024x864 1 Atelectasis, 1 Other lesion, 1 Aortic enlargement, 1 Infiltration, 1 Consolidation, 1 Pneumothorax, Done. (0.179s)\n",
      "image 10/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c803c4810a8c5ec362f5d4504489431.jpg: 1024x864 1 Atelectasis, 1 Other lesion, 2 Pneumothoraxs, Done. (0.171s)\n",
      "image 11/11 /home/ubuntu/vinbigdata/11DemoConversionToJPG/0c84dad44979c3a7777a8f4f4d9f5f7a.jpg: 1024x864 1 Atelectasis, 1 Other lesion, Done. (0.171s)\n",
      "Speed: 0.5ms pre-process, 178.8ms inference, 1.3ms NMS per image at shape (1, 3, 1024, 1024)\n",
      "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n",
      "11 labels saved to runs/detect/exp/labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09873632f34242a89b4c773c5f9ef86d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11\n",
      "Time to send prediction string and prediction images to SingleStore: 0.34 seconds\n",
      "CPU times: user 454 ms, sys: 59.9 ms, total: 514 ms\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# Bring Dicom metadata back from SingleStore\n",
    "\n",
    "\n",
    "os.chdir('/home/ubuntu/vinbigdata/')\n",
    "s2conn = create_engine('mysql+pymysql://root:Sglstrpw34@172.31.62.112:3306/PatientRecords')\n",
    "\n",
    "test_df = pd.read_sql_table('ImageHeaderdf', s2conn)\n",
    "\n",
    "\n",
    "# Run Yolov5 Ensemble model on new JPG folder\n",
    "\n",
    "\n",
    "fold_exp = ['exp26']\n",
    "test_dir = f'/home/ubuntu/vinbigdata/11DemoConversionToJPG/'\n",
    "os.chdir('/home/ubuntu/vinbigdata/yolov5')\n",
    "\n",
    "for fold, exp in enumerate(fold_exp):\n",
    "    weights_dir = '''/home/ubuntu/vinbigdata/yolov5/runs/train/exp26/weights/best.pt \\\n",
    "/home/ubuntu/vinbigdata/yolov5/runs/train/exp27/weights/best.pt \\\n",
    "/home/ubuntu/vinbigdata/yolov5/runs/train/exp28/weights/best.pt \\\n",
    "/home/ubuntu/vinbigdata/yolov5/runs/train/exp29/weights/best.pt \\\n",
    "/home/ubuntu/vinbigdata/yolov5/runs/train/exp30/weights/best.pt'''\n",
    "    \n",
    "    os.chdir('/home/ubuntu/vinbigdata/yolov5/')\n",
    "    \n",
    "    !python detect.py --weights $weights_dir\\\n",
    "    --img 1024\\\n",
    "    --conf 0.2\\\n",
    "    --iou 0.4\\\n",
    "    --source $test_dir\\\n",
    "    --save-txt --save-conf --exist-ok\n",
    "    \n",
    "\n",
    "# Convert Yolo predictions to PascalVoc format, back to the original Dicom Size\n",
    "    \n",
    "    \n",
    "    image_ids = []\n",
    "    PredictionStrings = []\n",
    "\n",
    "    for file_path in tqdm(glob('runs/detect/exp/labels/*txt')):\n",
    "        image_id = file_path.split('/')[-1].split('.')[0]\n",
    "        w, h = test_df.loc[test_df.file==image_id,['Columns', 'Rows']].values[0]\n",
    "        f = open(file_path, 'r')\n",
    "        data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n",
    "        data = data[:, [0, 5, 1, 2, 3, 4]]\n",
    "        bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 1).astype(str))\n",
    "        for idx in range(len(bboxes)):\n",
    "            bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n",
    "        image_ids.append(image_id)\n",
    "        PredictionStrings.append(' '.join(bboxes))\n",
    "\n",
    "    # credit / source: https://www.kaggle.com/awsaf49/vinbigdata-cxr-ad-yolov5-14-class-infer\n",
    "    pred_df = pd.DataFrame({'file':image_ids,\n",
    "                            'PredictionString':PredictionStrings})\n",
    "    df = pd.merge(test_df, pred_df, on = 'file', how = 'left').fillna(\"14 1 0 0 1 1\")\n",
    "    df = df[['file', 'PredictionString']]\n",
    "\n",
    "    os.chdir('/home/ubuntu/vinbigdata/')\n",
    "    \n",
    "\n",
    "# Send images with predictions to SingleStore. Starting timer\n",
    "start = time.time()\n",
    "\n",
    "directory = '/home/ubuntu/vinbigdata/yolov5/runs/detect/exp'\n",
    "jpgCount = 0\n",
    "\n",
    "\n",
    "\n",
    "s2conn = pymysql.connect(\n",
    "    user='root',\n",
    "    password='Sglstrpw34',\n",
    "    host='172.31.62.112',\n",
    "    port=3306,\n",
    "    database='Images')\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        file = os.path.splitext(os.path.basename(os.path.basename(f)))[0]\n",
    "\n",
    "        # checking if it is a file\n",
    "        if os.path.isfile(f) and f.endswith(\".jpg\"):\n",
    "            updateBLOB(file, directory, f)\n",
    "            jpgCount += 1\n",
    "            if jpgCount % 100 == 0:\n",
    "                print (jpgCount)\n",
    "print(jpgCount)\n",
    "s2conn.close()\n",
    "\n",
    "\n",
    "# Clear image prediction folders for reusability\n",
    "\n",
    "\n",
    "dir = '/home/ubuntu/vinbigdata/yolov5/runs/detect/exp/'\n",
    "for files in os.listdir(dir):\n",
    "    path = os.path.join(dir, files)\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except OSError:\n",
    "        os.remove(path)\n",
    "        \n",
    "\n",
    "# Send prediction strings to SingleStore\n",
    "\n",
    "\n",
    "s2conn = pymysql.connect(\n",
    "    user='root',\n",
    "    password='Sglstrpw34',\n",
    "    host='172.31.62.112',\n",
    "    port=3306,\n",
    "    database='PatientRecords')\n",
    "\n",
    "for ind in df.index:\n",
    "    InFile = df['file'][ind]\n",
    "    InPredictionString = df['PredictionString'][ind]\n",
    "    mycursor = s2conn.cursor()\n",
    "    sql = \"call InsertImagePredictions('\" + InFile + \"','\" + InPredictionString + \"')\"\n",
    "    mycursor.execute(sql)\n",
    "    s2conn.commit()\n",
    "  \n",
    "mycursor.close()\n",
    "s2conn.close()\n",
    "end = time.time()\n",
    "print(f'Time to send prediction string and prediction images to SingleStore: {round((end - start),2)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89215fe-1020-4870-a09a-5a65856b2e8b",
   "metadata": {},
   "source": [
    "- [Back to Contents](#contents2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
